# -*- coding: utf-8 -*-
"""ClasificationData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1al35NLEBpEWaznjhspNgqViI85C3ef0e

#Decision Tree
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('diabetes.csv', delimiter=',', header=(0))

df

df.info()

"""# Modeling"""

# Menentukan variabel x dan y

feature_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
X = df[feature_cols]
Y = df['Outcome']

# Split Data

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)

"""# Decision Tree Standard"""

from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier()
clf = clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

from sklearn import metrics

print("Akurasi Decision Tree Standard;", metrics.accuracy_score(y_test, y_pred))
# y_test adalah kelas actual/sebenarnya, y_pred adalah kelas prediksi

from sklearn import tree

fig = plt.figure(figsize=(25,20))
tree.plot_tree(clf, filled = True)

clf_prun = DecisionTreeClassifier(criterion='entropy', max_depth=3)
clf_prun = clf_prun.fit(x_train, y_train)

y_pred_prun = clf_prun.predict(x_test)

print('Akurasi Decision Tree dengan Pruning:', metrics.accuracy_score(y_test, y_pred_prun))

fig = plt.figure(figsize=(25, 20))
tree.plot_tree(clf_prun, filled=True)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf = rf.fit(x_train, y_train)
y_pred_rf = rf.predict(x_test)

print('Akurasi Random Forest tanpa Pruning: ', metrics.accuracy_score(y_test, y_pred_rf))

rf_prun = RandomForestClassifier(criterion = 'entropy', max_depth=3, max_leaf_nodes=5, class_weight=None)
rf_prun = rf_prun.fit(x_train, y_train)
y_pred_rf_prun = rf_prun.predict(x_test)

print('Akurasi Random Forest dengan Pruning: ', metrics.accuracy_score(y_test, y_pred_rf_prun))

fig = plt.figure(figsize=(25,20))
tree.plot_tree(rf_prun.estimators_[0], filled = True)

"""# Feature Importance"""

importance = rf.feature_importances_

for i, v in enumerate(importance):
    print('Feature: %0d, Score: %.5f' % (i, v))

plt.bar([x for x in range(len(importance))], importance)
plt.show()

importance_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'Age']

# Bagi ke x dan y
X1 = df[importance_cols]

x1_train, x1_test, y1_train, y1_test = train_test_split(X1, Y, test_size=0.3, random_state=1)

rf1 = RandomForestClassifier()
rf1 = rf1.fit(x1_train, y1_train)
y1_pred = rf1.predict(x1_test)

print('Akurasi RF dengan Importance: ', metrics.accuracy_score(y1_test, y1_pred))

"""# Classification SVM"""

df = pd.read_csv('customers.csv')

df

df.info()

feature_df = df[['Region', 'Fresh', 'Milk', 'Grocery', 'Frozen', 'Detergents_Paper', 'Delicassen']]
X_cust = np.asarray(feature_df)
X_cust[0:5]

# Target adalah Channel

df['Channel'] = df['Channel'].astype('int')
Y_cust = np.asarray(df['Channel'])
Y_cust[0:5]

"""Modeling SVM"""

xcust_train, xcust_test, ycust_train, ycust_test = train_test_split(X_cust, Y_cust, test_size=0.2, random_state=1)

# Kernel RBF
from sklearn import svm

svm_rbf = svm.SVC(kernel='rbf')
svm_rbf.fit(xcust_train, ycust_train)

y_pred_svm1 = svm_rbf.predict(xcust_test)

from sklearn.metrics import classification_report, confusion_matrix

cm_rbf = confusion_matrix(ycust_test, y_pred_svm1)

print(classification_report(ycust_test, y_pred_svm1))

# Kernel Linear
svm_linear = svm.SVC(kernel='linear')
svm_linear.fit(xcust_train, ycust_train)

y_pred_svm2 = svm_linear.predict(xcust_test)


cm_linear = confusion_matrix(ycust_test, y_pred_svm2)

print(classification_report(ycust_test, y_pred_svm2))

# Kernel Poly
svm_poly = svm.SVC(kernel='poly')
svm_poly.fit(xcust_train, ycust_train)

y_pred_svm3 = svm_poly.predict(xcust_test)

cm_poly = confusion_matrix(ycust_test, y_pred_svm3)

print(classification_report(ycust_test, y_pred_svm3))

